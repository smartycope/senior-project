[
  {
    "objectID": "posts/SquarePacking/index.html",
    "href": "posts/SquarePacking/index.html",
    "title": "Square Packing",
    "section": "",
    "text": "My senior project is to attempt to use a reinforcement learning algorithm based on a Deep Deterministic Policy Gradient model for use with a continuous observation and action space, in order to solve the Square Packing in a Square problem for N=11 squares.\nThat was a very intelligent sounding sentence. Let’s break it down:\n\nSquare Packing in a Square\nThe Square Packing in a Square problem is an unsolved problem in mathematics where the goal is to pack N squares with a side length of 1 into another square, while wasting as little space as possible.\nThe technical wording is\n\nWhat is the asymptotic growth rate of wasted space for square packing in a half-integer square?\n\nI’m not going to be solving that. Instead I’m going to attempt to use Reinforcement Learning (RL) to attempt to figure out a better solution for me. I have no idea how well it will work.\nThere are known configurations for N=1-10 squares, but 11 (and some others) are only approximately solved. This tries to find a more optimal configuration for N=11 squares by using RL instead of pure math.\nThe theoretial optimal packing has a side length of 3.789, but the best known is 3.877084\n\n\n\nDDPG\nDDPG model is a kind of actor-critic setup (not technically a model) that allows continuous rather than discrete observation and action spaces. This is important, because I want to find a very precise solution, as opposed to infinitely increasing the discrete resolution of steps the AI can take.\nAn actor-critic setup has 2 models (though the DDPG setup has 4, for training purposes). One model is the actor, which takes in an observation from the enviorment, learns to outputs actions to take in the enviorment, optimized to some reward function. The other model takes in an observation from the enviorment and the action taken by the actor for that observation, and learns to output the reward that that action will get for that observation. The actor model can then use the output of the critic model to train itself.\nIt’s kind of like learning to dance to a song on a stage based on some guy in the back either clapping or yelling “boooo!”. Eventually you can start to understand what the critic is asking for.\nThis is the fundemental equation behind the DDPG algorithm. I understood it at one point, but have since forgot. See the above links for a real explanation.\n\n\n\nImplementation\nBoth the action and observation spaces will have the shape (3*N, ) (N is the number of squares, so 11) where each square has an x, y and rotation values. The actor’s actions simply get added to the current square positions and rotations (since the actor actions can be negative), so the actor can make small adjustments to squeze the squares closer to each other.\nThe reward function hasn’t been developed yet, but it will involve something like steeply punishing overlapping squares, and incentivizing smaller “bounding square” side lengths (like a bounding rectangle, but a square).\nI’ll be using Shapely for the geometry handling:\n\n\nCode\n# This is an example of converting the action space into a shapely object\nMultiPolygon(convert2shapely([(random.uniform(0, space), random.uniform(0, space), random.uniform(1, 2*math.pi)) for i in range(N)], side_len=scale))\n\n\n\n\n\n\n\n\n\nI’ll use Tensorflow for the models, this is my proposed actor network structure:\n\nAnd for the RL enviorment, I’ll use the popular Gymnasium library, specifically my own personal SimpleGym class which is a helpful abstraction on top of gymnasium:"
  },
  {
    "objectID": "posts/GeoDoodle/index.html",
    "href": "posts/GeoDoodle/index.html",
    "title": "GeoDoodle",
    "section": "",
    "text": "I love doodling on graph paper.\nIt’s just something I’ve done for a long time, since I was a kid. It’s something to keep my hands busy while I sit in church or class. It occupies just enough of my mind to keep me entertained, but not too much that I can’t pay attention. It’s perfect.\nAnd over the years, I’ve gotten pretty good, if I don’t say so myself. I have something like 3 or 4 notebooks full of these sorts of patterns:\n    \nBut that’s the problem, isn’t it. They’re in notebooks. I’m not even sure where they are. I don’t look at them or add to them anymore.\n\nHistory\nEver since my very 2nd programming class (the first class was all terminal based), I had the idea for “automated graph paper”. All the lines line up with the dots. It wouldn’t be that difficult to make a program that had a bunch of dots and let you draw lines between them. Back then I had grand ideas of mirroring, selecting, copy/pasting, and repeating lines, but I didn’t have any way to execute them. I had an old, outdated, unsupported (even back then) freeGLUT C++ framework that my class gave me that I hacked together to show an array of dots on the screen, and was barely able to connect lines between them. And then the house of cards that was my code fell apart and I moved onto other things.\nAbout a year later, after starting many other projects, and knowing way, way more, I discovered Python. I realized that my old idea I loved so much was still a cool idea, and I got excited and I ended up scrapping the entire codebase and rewriting the entire thing from scratch in Python (using pygame). I got it roughtly to where it was before, in about 4 hours. It’s pretty cool to see yourself improve in such an obvious way. I then added a bunch more features and made everything a lot nicer (pygame is an excellent API), including adding menus and options and a better repeating system. I eventually got stymied by the GUI though. At that point I hadn’t really done much with GUI’s, and I tried using pygame-gui, which isn’t a bad API, it’s just really not meant for what I wanted. I ended up writing huge, very nasty wrappers around their classes and it just wasn’t worth it. It again, became a house of cards and I saw that.\nA couple months later, I had the idea to use Qt. It was something I’d wanted to learn for a while, but I never really had a project suited to it, until I realized this was perfect. Turns out, Qt is fantastic. There’s a reason it’s so popular. It definitely takes some getting used to, but it’s all very clean, and QtCreator is super handy. Using Qt allowed me to expand even further, and add more features far more intuitively.\nA few months after that, I took a linear algebra course and had the realization that a bunch of the problems I had with repeating patterns and keeping track of coordinates could all be solved by using matrices for coordinates and multiplying by a transformation matrix. I then rewrote the whole codebase (again) to use numpy to represent dots and lines instead. That solved a ton of conceptual problems, and allowed me to add a bunch of features like mirroring and rotating and scaling. It also cleaned a the code up a ton too. That time it wasn’t a total rewrite, because I was able to re-use a lot of the PyQt GUI elements.\nThis is the last working version of GeoDoodle I had in Python \nAll these versions had a few shared, fundemental problems, however:\n\nThe coordinate systems where complicated. Even after I switched to using proper linear algebra, it was still complicated to keep track of, and involved writing my own coordinate system & utilies, essentially.\nDeployment. I love Python to pieces, and it’s the optimal programming language for a lot of things, but it really doesn’t deploy to other platforms very well. I always wanted to show my friends & family my cool program, but I never could, because trying to say “go into the terminal, git clone my repo, install python, and run the main.py file” really isn’t possible for my non-tech savvy mother. I tried a few things like pyqt5deploy and the Qt for Android tutorials, but I couldn’t get them to work\nEfficiency. When a pattern we want to repeat is small enough (meaning that more of them fit on the screen), and has too many lines in it, that means we could be drawing up to hundreds or thousands of lines on the screen, and if I want the user to be able to move around or add lines, depending on how I do it, that could mean they have to update in real-time. This was obviously a problem for freeGLUT (where I had to make raw OpenGL commands, which I didn’t know how to do correctly), and pygame (which isn’t really optimized for that sort of thing), but for PyQt you might not think it would be a problem. It was certainly better than the first 2, but it still got unusably slow under those conditions. I tried optimizing using OpenGL, but that only led down a deeper rabit hole I didn’t really want to go down.\n\n\n\nEnter: JavaScript\nRecently (as of this post) I got an internship writing TypeScript React code. I previously didn’t know Java/TypeScript, so I had a couple week long crash course on JS programming before I started. After I started, I immediately realized the potential JavaScript holds. Not because it’s good or proper (I think JS is terribly janky sometimes), but because it’s not. JS is geared towards writing UIs, which it does well. And part of UIs seems to be inherent jankiness, it seems. Lambda’s galore, strange, optional syntax (semicolons aren’t required, but everyone uses them anyway??), and objects that don’t act like objects in any other language I’d learned. It’s almost as if JS isn’t Object-Oriented, but instead Event-Oriented.\nHowever it has a number of key advantages. Aside from being made for making UIs, like I mentioned, it’s supported everywhere and is made for deployment. Very quickly after learning it I made a couple projects, including Debate-Tracker, and EZRegex. I then realized: my favorite project, my “unique” idea (I haven’t researched if it actually is, and I don’t intend to), GeoDoodle, is perfect for JS. The project is largely UI elements, once the base part is done, I wanted to use it from both my computer and my phone, and SVG is the natural format for the project. Given that HTML integrates seemlessly with SVG, React was perfect.\nSo of course, I started from scratch and rewrote the whole thing again from the ground up in another language. It’s a lot easier the 4th (5th?) time you do it, because you know beforehand what a lot of the problems you’re going to run into are, and how to solve them, and you also know what you need to do in order to generalize things for future features so you don’t end up refactoring your code too many times.\nI quickly got an MVP working (after a weekend of working on it obsessively), and kept adding to it. It now has multiple menus, including a controls menu instead of just using keyboard shortcuts, a help menu with a guided tour (surprisingly easy to make), multiple kinds of mirroring (you’d think it would be simple, but it’s more complex than you think), file saving, either natively to SVG files or to the local storage, basic repeating (is what I’m working on right now), and more. You can check it out at smartycope.github.io/geodoodle. I have it hosted on GitHub pages, and eventually I’ll probably by a URL for it to live at.\nThis time, I think I finally got it right. The code is clean and maintainable enough that I think when I inevitably come back to it in a year or so after I lose intrest, I’ll be able to pick it up again and just add features to it instead of rewriting it again. And the fact that I actually know how to use git now helps with that as well.\nYou can try it here, if you’d like:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Copeland Carter\n\nSoftware Engineer | Full Stack Developer | Data Engineer\n\nCheck out my projects on GitHub, or some of my published projects:\n\nRegular Expression genererator, and more: EZRegex\nA unique drawing program that acts like graph paper: GeoDoodle\n\nFeel free to email me at smartycope@gmail.com"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Copeland Carter’s Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nInstalling Tensorflow\n\n\n\n\n\n\npython\n\n\nML\n\n\n\n\n\n\n\n\n\nSep 24, 2026\n\n\nCopeland Carter\n\n\n\n\n\n\n\n\n\n\n\n\nGeoDoodle\n\n\n\n\n\n\nprojects\n\n\nopen source\n\n\njavascript\n\n\n\n\n\n\n\n\n\nMay 15, 2024\n\n\nCopeland Carter\n\n\n\n\n\n\n\n\n\n\n\n\nSquare Packing\n\n\n\n\n\n\nproject\n\n\npython\n\n\nML\n\n\n\n\n\n\n\n\n\nApr 30, 2024\n\n\nCopeland Carter\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/InstallingTensorflow/index.html",
    "href": "posts/InstallingTensorflow/index.html",
    "title": "Installing Tensorflow",
    "section": "",
    "text": "Getting tensorflow to use hardware acceleration is challenging. There’s plenty of tutorials to show you how to do it, but I’ve found that most of them lack sufficient detail, aren’t targeted towards what I’m doing (they’re made for super computing clusters or fine-grain control, or something), or are outdated. The ML field is moving fast right now, and things get outdated fast.\nWell, here’s yet another blog post. This is what I did to get tensorflow to connect to my GPU, maybe it’ll help you.\n\nHardware\nFirst off, some hardware. Tensorflow seems to work best on NVIDIA GPUs. I’m told it’s possible to get it to work on an AMD GPU, but the one time I tried, I couldn’t get it to work. You can see this for-pay article for more guidance, in that case.\nHere’s my screenfetch: \n\n\nGuide\nWhen I set it up, I followed this blog post. It contains a lot of good detail, so instead of repeating everything it says, just follow it, and I’ll tell you what I had to change to get it to work.\nWhen installing drivers, I installed nvidia-driver-550, and then had to restart to activate it, which isn’t in the tutorial. According to this page, anything &gt;=520.;61.05 should work. Later on, while trying to debug the later steps, I ended up installing 525 as well, however, I don’t think that actually fixed anything.\nI also had to install the cuda-toolkit package (sudo apt install cuda-toolkit) to get it to run, which isn’t mentioned in the post.\nInstead of the versions specified in the post, I used these versions specifically:\n\npython3.11\ncuDNN==8.8\ncudatoolkit==11.8\ntensorflow==2.14\n\nNOTE: The cudatoolkit version is the version of the Python package; upon running nvidia-smi, my driver says it’s CUDA version 12.2. This didn’t seem to cause problems.\nI used this table from the post to align all the versions. I had a bit of a problem, because as of 5/22/24, cuDNN==8.7 doesn’t exist on conda for some reason, and cudatoolkit&gt;=12 was not released on conda yet, so had to use python3.11 and guess at some of the package versions, but the ones I used worked out.\nAfter following all the steps in the post and running the benchmark test mentioned, it threw and error with a bunch of warnings and errors and traceback and other stuff. After digging through it and some research, I found this stackoverflow post that advised running this command:\nexport XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\nwhich worked. You may want to follow the steps in the article to find your specific cuda installation path, but it’s likely /usr/lib/cuda. You’ll also likely want to put that line in your ~/.bashrc file, so it will work in other terminals as well.\nMy benchmarks were:\n\nGPU: 17.934 seconds\nCPU: 219.757 seconds\n\nA 12.25x speedup! Not bad!\n\n\nPhoto courtesy of Coding for Entrepreneurs"
  }
]